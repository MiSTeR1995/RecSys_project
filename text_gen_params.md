# Памятка по параметрам генерации текста

## Основные параметры

### 1. `max_new_tokens`
- **Описание**: Определяет максимальное количество новых токенов (слов, символов или частей слов), которые модель может сгенерировать в ответ на запрос. Этот параметр контролирует длину выходного текста.
- **Пример использования**: `max_new_tokens=50` — модель генерирует не более 50 новых токенов.
- **Когда использовать**: Если вам нужно ограничить длину ответа, например, при генерации кратких ответов или ключевых слов.

### 2. `num_return_sequences`
- **Описание**: Указывает количество генерируемых последовательностей. Например, если `num_return_sequences=3`, модель вернет три разных варианта ответа.
- **Пример использования**: `num_return_sequences=1` — модель генерирует только одну последовательность.
- **Когда использовать**: Если нужно получить несколько вариантов ответа, чтобы выбрать лучший или дать пользователю выбор.

### 3. `do_sample`
- **Описание**: Определяет, следует ли использовать сэмплирование при генерации текста. Сэмплирование добавляет случайности, что позволяет модели генерировать более разнообразные ответы.
- **Пример использования**: `do_sample=True` — включено сэмплирование, `do_sample=False` — модель всегда выбирает наиболее вероятный токен.
- **Когда использовать**: Включайте сэмплирование, если хотите получить разнообразные и менее предсказуемые ответы, например, для творческих задач или генерации текста, где важна вариативность.

### 4. `top_k`
- **Описание**: Контролирует выбор следующего токена из `k` наиболее вероятных вариантов. Если `top_k=10`, модель выбирает следующий токен из 10 наиболее вероятных токенов.
- **Пример использования**: `top_k=10` — модель выбирает из 10 лучших токенов.
- **Когда использовать**: Используйте, если хотите ограничить случайность, сохраняя только наиболее вероятные варианты, но при этом сохранить некоторое разнообразие в ответах.

### 5. `top_p` (Nucleus Sampling)
- **Описание**: Определяет порог вероятности для выборки токенов. Модель выбирает токены, сумма вероятностей которых равна или превышает `p`. Например, если `top_p=0.9`, модель выбирает токены, которые в сумме составляют 90% вероятности.
- **Пример использования**: `top_p=0.9` — модель выбирает из множества токенов, сумма вероятностей которых составляет 90%.
- **Когда использовать**: Этот параметр помогает создать баланс между предсказуемостью и разнообразием. Используйте его, если хотите получить ответы с высокой вероятностью, но избежать слишком узкого выбора токенов.

## Дополнительные параметры

### 6. `temperature`
- **Описание**: Управляет случайностью генерации. Низкие значения (например, 0.7) делают текст более предсказуемым, высокие значения (например, 1.5) делают текст более случайным.
- **Пример использования**: `temperature=0.8` — модель генерирует текст с умеренной случайностью.
- **Когда использовать**: Если хотите увеличить или уменьшить креативность и неожиданность ответов. Высокие значения позволяют получить более разнообразные и неожиданные ответы.

### 7. `repetition_penalty`
- **Описание**: Штраф за повторение одинаковых токенов или фраз. Значение больше 1.0 снижает вероятность повторения, что помогает избежать однообразия в тексте.
- **Пример использования**: `repetition_penalty=1.2` — модель штрафует повторения и избегает их.
- **Когда использовать**: Используйте, если хотите предотвратить повторение одних и тех же слов или фраз, особенно в длинных текстах.

### 8. `min_length`
- **Описание**: Задает минимальное количество токенов в сгенерированном тексте. Модель не остановится, пока не достигнет этого значения.
- **Пример использования**: `min_length=10` — модель генерирует не менее 10 токенов.
- **Когда использовать**: Полезно, если вы хотите гарантировать, что ответ будет содержать определенное минимальное количество информации.

### 9. `length_penalty`
- **Описание**: Влияет на предпочтение длины текста. Значения больше 1.0 (например, 2.0) заставляют модель генерировать более длинные ответы, значения меньше 1.0 — более короткие.
- **Пример использования**: `length_penalty=1.5` — модель предпочитает более длинные ответы.
- **Когда использовать**: Используйте для контроля длины ответа. Например, можно сделать ответы более лаконичными или более развернутыми.


# Памятка по параметрам `quantization_method` в `BitsAndBytesConfig`

## Доступные методы квантования

### 1. **`gptq`** (Gradient Post-Training Quantization)
- **Описание**: Этот метод применяется после тренировки модели и использует градиентные методы для минимизации потерь при квантовании. Он позволяет сохранить высокую точность модели при снижении разрядности до 4 или 8 бит.
- **Когда использовать**: Если важна минимизация потерь точности при квантовании уже обученной модели.

### 2. **`fake_quant`** (Fake Quantization)
- **Описание**: Этот метод используется для имитации квантования во время тренировки модели. Он не снижает разрядность данных, а лишь симулирует эффект квантования для оценки его влияния на модель.
- **Когда использовать**: Если нужно предварительно оценить, как квантование повлияет на модель перед его фактическим применением.

### 3. **`dynamic`** (Dynamic Quantization)
- **Описание**: Динамическое квантование сохраняет веса модели в высокоточном формате, но выполняет вычисления в более низкой разрядности (например, 8-бит). Это снижает объем памяти, необходимый для выполнения модели, и ускоряет выполнение операций.
- **Когда использовать**: Если требуется ускорение выполнения модели с минимальной потерей точности, особенно на устройствах с ограниченными ресурсами.

### 4. **`static`** (Static Quantization)
- **Описание**: В статическом квантовании и веса, и активации модели квантованы до более низкой разрядности. Это позволяет выполнить все вычисления в более низкой разрядности, что значительно снижает объем памяти и повышает производительность.
- **Когда использовать**: Для задач, где важно максимальное снижение объема памяти и повышение производительности, особенно в встроенных системах.

### 5. **`qat`** (Quantization-Aware Training)
- **Описание**: Этот метод требует тренировки модели с учетом предстоящего квантования. Модель обучается с учетом ограничений, которые вводятся квантованием, что позволяет минимизировать потери точности.
- **Когда использовать**: Если вы можете тренировать модель с нуля и хотите минимизировать потери точности после квантования.
